{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d4cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage, ToolMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents import Tool\n",
    "import langgraph.pregel\n",
    "import importlib.util\n",
    "import yaml\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import SystemMessage, AIMessage\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "# from langchain.agents.agent_toolkits import ToolNode\n",
    "# import importlib.util\n",
    "import os\n",
    "import yaml\n",
    "from typing import List, Dict, Any\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.pregel import BaseChannel\n",
    "from langchain_core.messages import HumanMessage\n",
    "import re\n",
    "from typing import TypedDict, Sequence, Annotated\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "import yaml\n",
    "import importlib.util\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_core.tools import tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a7c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc587ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LangGraph Multi-turn Chatbot ===\n",
      "===========================LLM Node Invoked================================\n",
      "-------------------------Current Messages: {'messages': [{'role': 'user', 'content': 'Hello!'}], 'steps': 0, 'tools_used': []} -----------------------\n",
      "===========================Router Node Invoked================================\n",
      "========================Routing to: end========================================\n",
      "========================Router Output: {'messages': [{'role': 'user', 'content': 'Hello!'}, {'role': 'assistant', 'content': 'Hello! How can I help you today?'}], 'steps': 1, 'tools_used': [], '__graph_path__': 'end'}========================================\n",
      "AI: Hello! How can I help you today?\n",
      "===========================LLM Node Invoked================================\n",
      "-------------------------Current Messages: {'messages': [{'role': 'user', 'content': 'Hello!'}, {'role': 'assistant', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': 'what is time now?'}], 'steps': 1, 'tools_used': []} -----------------------\n",
      "===========================Router Node Invoked================================\n",
      "========================Routing to: tool========================================\n",
      "========================Router Output: {'messages': [{'role': 'user', 'content': 'Hello!'}, {'role': 'assistant', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': 'what is time now?'}, {'role': 'assistant', 'content': 'The current time is **10:07 AM UTC** on Thursday, May 23, 2024.\\n\\nPlease note that this is Coordinated Universal Time (UTC). Your local time may be different depending on your time zone.'}], 'steps': 2, 'tools_used': [], '__graph_path__': 'tool'}========================================\n",
      "===========================Tool Node Invoked================================\n",
      "-----------------------User Message: the current time is **10:07 am utc** on thursday, may 23, 2024.\n",
      "\n",
      "please note that this is coordinated universal time (utc). your local time may be different depending on your time zone. -----------------------\n",
      "=====================================,hi,=====================================\n",
      "===========================Get Time Tool Invoked================================\n",
      "===========================End Check Node Invoked================================\n",
      "===========================LLM Node Invoked================================\n",
      "-------------------------Current Messages: {'messages': [{'role': 'user', 'content': 'Hello!'}, {'role': 'assistant', 'content': 'Hello! How can I help you today?'}, {'role': 'user', 'content': 'what is time now?'}, {'role': 'assistant', 'content': 'The current time is **10:07 AM UTC** on Thursday, May 23, 2024.\\n\\nPlease note that this is Coordinated Universal Time (UTC). Your local time may be different depending on your time zone.'}, {'role': 'tool', 'content': 'The time is 10:08:47'}], 'steps': 2, 'tools_used': ['The time is 10:08:47']} -----------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tool_call_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 214\u001b[39m\n\u001b[32m    207\u001b[39m state: GraphState = {\n\u001b[32m    208\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHello!\u001b[39m\u001b[33m\"\u001b[39m}],\n\u001b[32m    209\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msteps\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m,\n\u001b[32m    210\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtools_used\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m    211\u001b[39m }\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     state = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m     latest = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    216\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAI:\u001b[39m\u001b[33m\"\u001b[39m, latest)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2534\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2533\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m loop.after_tick()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mllm_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m===========================LLM Node Invoked================================\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-------------------------Current Messages:\u001b[39m\u001b[33m\"\u001b[39m, state, \u001b[33m\"\u001b[39m\u001b[33m-----------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This returns an AIMessage or dict?\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# You must append a dict with role and content\u001b[39;00m\n\u001b[32m     86\u001b[39m \n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# If llm.invoke returns a LangChain Message object, convert to dict:\u001b[39;00m\n\u001b[32m     88\u001b[39m new_msg = {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: response}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langchain_core/language_models/llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    380\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m     **kwargs: Any,\n\u001b[32m    386\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    387\u001b[39m     config = ensure_config(config)\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    389\u001b[39m         \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[32m    391\u001b[39m             stop=stop,\n\u001b[32m    392\u001b[39m             callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    393\u001b[39m             tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    394\u001b[39m             metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    395\u001b[39m             run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    396\u001b[39m             run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    397\u001b[39m             **kwargs,\n\u001b[32m    398\u001b[39m         )\n\u001b[32m    399\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    400\u001b[39m         .text\n\u001b[32m    401\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langchain_core/language_models/llms.py:336\u001b[39m, in \u001b[36mBaseLLM._convert_input\u001b[39m\u001b[34m(self, model_input)\u001b[39m\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m StringPromptValue(text=model_input)\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_input, Sequence):\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=\u001b[43mconvert_to_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    337\u001b[39m msg = (\n\u001b[32m    338\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m )\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langchain_core/messages/utils.py:367\u001b[39m, in \u001b[36mconvert_to_messages\u001b[39m\u001b[34m(messages)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(messages, PromptValue):\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m messages.to_messages()\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langchain_core/messages/utils.py:340\u001b[39m, in \u001b[36m_convert_to_message\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m    336\u001b[39m         msg = create_message(\n\u001b[32m    337\u001b[39m             message=msg, error_code=ErrorCode.MESSAGE_COERCION_FAILURE\n\u001b[32m    338\u001b[39m         )\n\u001b[32m    339\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     _message = \u001b[43m_create_message_from_message_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmsg_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmsg_kwargs\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    344\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported message type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langchain_core/messages/utils.py:283\u001b[39m, in \u001b[36m_create_message_from_message_type\u001b[39m\u001b[34m(message_type, content, name, tool_call_id, tool_calls, id, **additional_kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m message_type == \u001b[33m\"\u001b[39m\u001b[33mtool\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    282\u001b[39m     artifact = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33madditional_kwargs\u001b[39m\u001b[33m\"\u001b[39m, {}).pop(\u001b[33m\"\u001b[39m\u001b[33martifact\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     message = \u001b[43mToolMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m message_type == \u001b[33m\"\u001b[39m\u001b[33mremove\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    285\u001b[39m     message = RemoveMessage(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langchain_core/messages/tool.py:146\u001b[39m, in \u001b[36mToolMessage.__init__\u001b[39m\u001b[34m(self, content, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mself\u001b[39m, content: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]]], **kwargs: Any\n\u001b[32m    139\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    140\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a ToolMessage.\u001b[39;00m\n\u001b[32m    141\u001b[39m \n\u001b[32m    142\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m        content: The string contents of the message.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m        **kwargs: Additional fields.\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langchain_core/messages/base.py:72\u001b[39m, in \u001b[36mBaseMessage.__init__\u001b[39m\u001b[34m(self, content, **kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mself\u001b[39m, content: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]]], **kwargs: Any\n\u001b[32m     66\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     67\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Pass in content as positional arg.\u001b[39;00m\n\u001b[32m     68\u001b[39m \n\u001b[32m     69\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[33;03m        content: The string contents of the message.\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langchain_core/load/serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/dinith/Academic/.venv/lib/python3.13/site-packages/langchain_core/messages/tool.py:132\u001b[39m, in \u001b[36mToolMessage.coerce_args\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m tool_call_id = \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_call_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_call_id, (UUID, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[32m    134\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mtool_call_id\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(tool_call_id)\n",
      "\u001b[31mKeyError\u001b[39m: 'tool_call_id'",
      "During task with name 'llm' and id '95947750-48d5-b19d-a840-aca98ddc2363'"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Optional, List, Dict, Any\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Define State Schema\n",
    "# ---------------------------\n",
    "class GraphState(TypedDict):\n",
    "    messages: List[Dict[str, Any]]         # Full chat history (list of message dicts)\n",
    "    steps: Optional[int]                   # Number of steps taken\n",
    "    tools_used: Optional[List[str]]       # Tool outputs or logs\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Define Tools with Docstrings\n",
    "# ---------------------------\n",
    "@tool\n",
    "def get_time(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the current system time in HH:MM:SS format.\n",
    "\n",
    "    Parameters:\n",
    "        _: str â€“ ignored input (used for compatibility).\n",
    "\n",
    "    Returns:\n",
    "        str: Current time in formatted string.\n",
    "    \"\"\"\n",
    "    print(f\"=====================================,{x},=====================================\")\n",
    "    print(\"===========================Get Time Tool Invoked================================\")\n",
    "\n",
    "    from datetime import datetime\n",
    "    return f\"The time is {datetime.now().strftime('%H:%M:%S')}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calc(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluates a basic math expression and returns the result.\n",
    "\n",
    "    Parameters:\n",
    "        expression (str): A valid Python-style math expression (e.g., '2 + 2 * 3').\n",
    "\n",
    "    Returns:\n",
    "        str: Result of the expression, or an error message if invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return f\"The answer is {eval(expression)}\"\n",
    "    except:\n",
    "        return \"Invalid expression.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def tell_joke(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a single-line joke.\n",
    "\n",
    "    Parameters:\n",
    "        _: str â€“ ignored input (used for compatibility).\n",
    "\n",
    "    Returns:\n",
    "        str: A random joke string.\n",
    "    \"\"\"\n",
    "    return \"Why donâ€™t skeletons fight each other? Because they donâ€™t have the guts.\"\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Initialize LLM\n",
    "# ---------------------------\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA35dFqaffbE1bGiVDgs3joLRQI1bMetV0\" #dinitharrow\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.1)\n",
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Define Graph Nodes\n",
    "# ---------------------------\n",
    "\n",
    "def llm_node(state: GraphState) -> GraphState:\n",
    "    print(\"===========================LLM Node Invoked================================\")\n",
    "    print(\"-------------------------Current Messages:\", state, \"-----------------------\")\n",
    "    response = llm.invoke(state[\"messages\"])  # This returns an AIMessage or dict?\n",
    "    # You must append a dict with role and content\n",
    "\n",
    "    # If llm.invoke returns a LangChain Message object, convert to dict:\n",
    "    new_msg = {\"role\": \"assistant\", \"content\": response}\n",
    "\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [new_msg],\n",
    "        \"steps\": state.get(\"steps\", 0) + 1,\n",
    "        \"tools_used\": state.get(\"tools_used\", [])\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def tool_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Determines which tool to call based on last user message,\n",
    "    invokes the tool, and appends tool output to messages.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"===========================Tool Node Invoked================================\")\n",
    "    user_msg = state[\"messages\"][-1][\"content\"].lower()\n",
    "    print(\"-----------------------User Message:\", user_msg, \"-----------------------\")\n",
    "\n",
    "    if \"time\" in user_msg:\n",
    "\n",
    "        output = get_time.invoke(\"hi\")\n",
    "    elif \"math\" in user_msg:\n",
    "        expression = user_msg.replace(\"math\", \"\").strip()\n",
    "        output = calc.invoke(expression)\n",
    "    elif \"joke\" in user_msg:\n",
    "        output = tell_joke.invoke(\"\")\n",
    "    else:\n",
    "        output = \"Sorry, I don't understand the tool request.\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [{\"role\": \"tool\", \"content\": output}],\n",
    "        \"tools_used\": state.get(\"tools_used\", []) + [output],\n",
    "        \"steps\": state.get(\"steps\", 0)\n",
    "    }\n",
    "\n",
    "\n",
    "def router_node(state: GraphState) -> dict:\n",
    "    print(\"===========================Router Node Invoked================================\")\n",
    "    last_input = state[\"messages\"][-1][\"content\"].lower()\n",
    "\n",
    "    if \"bye\" in last_input:\n",
    "        path = \"end\"\n",
    "    elif any(keyword in last_input for keyword in [\"time\", \"math\", \"joke\"]):\n",
    "        path = \"tool\"\n",
    "    else:\n",
    "        path = \"end\"\n",
    "\n",
    "    print(f\"========================Routing to: {path}========================================\")\n",
    "    # Return the state unchanged but with special __graph_path__ key\n",
    "    \n",
    "    x={\n",
    "        **state,\n",
    "        \"__graph_path__\": path\n",
    "    }\n",
    "\n",
    "    print(f\"========================Router Output: {x}========================================\")\n",
    "    \n",
    "    return x \n",
    "\n",
    "\n",
    "def end_check(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Stops the conversation if step count exceeded, else continue with LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"===========================End Check Node Invoked================================\")\n",
    "    if state.get(\"steps\", 0) >= 10:\n",
    "        return \"end\"\n",
    "    return {\n",
    "        **state,\n",
    "        \"__graph_path__\": 'llm'\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Step 5: Build and Compile Graph\n",
    "# ---------------------------\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "graph.add_node(\"llm\", llm_node)\n",
    "graph.add_node(\"tool\", tool_node)\n",
    "graph.add_node(\"router\", router_node)\n",
    "graph.add_node(\"end_check\", end_check)\n",
    "\n",
    "graph.set_entry_point(\"llm\")\n",
    "\n",
    "graph.add_edge(\"llm\", \"router\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda state: state.get(\"__graph_path__\"),\n",
    "    {\n",
    "        \"tool\": \"tool\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "graph.add_edge(\"tool\", \"end_check\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"end_check\",\n",
    "    lambda state: state.get(\"__graph_path__\"), \n",
    "    {\n",
    "        \"llm\": \"llm\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Step 6: Run Chat Loop\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangGraph Multi-turn Chatbot ===\")\n",
    "    state: GraphState = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "        \"steps\": 0,\n",
    "        \"tools_used\": []\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        state = app.invoke(state)\n",
    "        latest = state[\"messages\"][-1][\"content\"]\n",
    "        print(\"AI:\", latest)\n",
    "\n",
    "        if \"bye\" in latest.lower() or state.get(\"steps\", 0) >= 10:\n",
    "            print(\"ðŸ‘‹ Conversation ended.\")\n",
    "            break\n",
    "\n",
    "        user_input = input(\"You: \")\n",
    "        state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd94c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
